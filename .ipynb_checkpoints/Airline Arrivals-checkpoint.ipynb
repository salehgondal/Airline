{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "#http://stat-computing.org/dataexpo/2009/the-data.html\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "from datetime import timedelta,date\n",
    "import datetime\n",
    "from sklearn import tree\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import graphviz\n",
    "from sklearn.tree import export_graphviz\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.ensemble import RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\saleh\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3057: DtypeWarning: Columns (21) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "# Data for the month of August in 2019 for all flights\n",
    "data = pd.read_csv('C:/Users/saleh/Desktop/Airline/241868859_T_ONTIME_REPORTING.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the head of the data get a feel for all the columns. We will only use 100k rows from the data to save computational time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>YEAR</th>\n",
       "      <th>MONTH</th>\n",
       "      <th>DAY_OF_MONTH</th>\n",
       "      <th>OP_UNIQUE_CARRIER</th>\n",
       "      <th>TAIL_NUM</th>\n",
       "      <th>OP_CARRIER_FL_NUM</th>\n",
       "      <th>ORIGIN</th>\n",
       "      <th>ORIGIN_CITY_NAME</th>\n",
       "      <th>ORIGIN_STATE_NM</th>\n",
       "      <th>DEST</th>\n",
       "      <th>...</th>\n",
       "      <th>DIVERTED</th>\n",
       "      <th>AIR_TIME</th>\n",
       "      <th>FLIGHTS</th>\n",
       "      <th>DISTANCE</th>\n",
       "      <th>CARRIER_DELAY</th>\n",
       "      <th>WEATHER_DELAY</th>\n",
       "      <th>NAS_DELAY</th>\n",
       "      <th>SECURITY_DELAY</th>\n",
       "      <th>LATE_AIRCRAFT_DELAY</th>\n",
       "      <th>Unnamed: 31</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>19905</th>\n",
       "      <td>2019</td>\n",
       "      <td>8</td>\n",
       "      <td>26</td>\n",
       "      <td>DL</td>\n",
       "      <td>N3732J</td>\n",
       "      <td>3014</td>\n",
       "      <td>FAI</td>\n",
       "      <td>Fairbanks, AK</td>\n",
       "      <td>Alaska</td>\n",
       "      <td>SEA</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>183.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1533.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92968</th>\n",
       "      <td>2019</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>WN</td>\n",
       "      <td>N7819A</td>\n",
       "      <td>1103</td>\n",
       "      <td>LAX</td>\n",
       "      <td>Los Angeles, CA</td>\n",
       "      <td>California</td>\n",
       "      <td>HOU</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>178.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1390.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87542</th>\n",
       "      <td>2019</td>\n",
       "      <td>8</td>\n",
       "      <td>30</td>\n",
       "      <td>AS</td>\n",
       "      <td>N549AS</td>\n",
       "      <td>68</td>\n",
       "      <td>SIT</td>\n",
       "      <td>Sitka, AK</td>\n",
       "      <td>Alaska</td>\n",
       "      <td>SEA</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>108.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>861.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107699</th>\n",
       "      <td>2019</td>\n",
       "      <td>8</td>\n",
       "      <td>14</td>\n",
       "      <td>WN</td>\n",
       "      <td>N243WN</td>\n",
       "      <td>331</td>\n",
       "      <td>DEN</td>\n",
       "      <td>Denver, CO</td>\n",
       "      <td>Colorado</td>\n",
       "      <td>OAK</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>125.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>957.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>317196</th>\n",
       "      <td>2019</td>\n",
       "      <td>8</td>\n",
       "      <td>29</td>\n",
       "      <td>YX</td>\n",
       "      <td>N632RW</td>\n",
       "      <td>3642</td>\n",
       "      <td>IAH</td>\n",
       "      <td>Houston, TX</td>\n",
       "      <td>Texas</td>\n",
       "      <td>ATL</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>91.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>689.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        YEAR  MONTH  DAY_OF_MONTH OP_UNIQUE_CARRIER TAIL_NUM  \\\n",
       "19905   2019      8            26                DL   N3732J   \n",
       "92968   2019      8             8                WN   N7819A   \n",
       "87542   2019      8            30                AS   N549AS   \n",
       "107699  2019      8            14                WN   N243WN   \n",
       "317196  2019      8            29                YX   N632RW   \n",
       "\n",
       "        OP_CARRIER_FL_NUM ORIGIN ORIGIN_CITY_NAME ORIGIN_STATE_NM DEST  ...  \\\n",
       "19905                3014    FAI    Fairbanks, AK          Alaska  SEA  ...   \n",
       "92968                1103    LAX  Los Angeles, CA      California  HOU  ...   \n",
       "87542                  68    SIT        Sitka, AK          Alaska  SEA  ...   \n",
       "107699                331    DEN       Denver, CO        Colorado  OAK  ...   \n",
       "317196               3642    IAH      Houston, TX           Texas  ATL  ...   \n",
       "\n",
       "       DIVERTED AIR_TIME  FLIGHTS  DISTANCE  CARRIER_DELAY  WEATHER_DELAY  \\\n",
       "19905       0.0    183.0      1.0    1533.0            NaN            NaN   \n",
       "92968       0.0    178.0      1.0    1390.0            NaN            NaN   \n",
       "87542       0.0    108.0      1.0     861.0            NaN            NaN   \n",
       "107699      0.0    125.0      1.0     957.0           12.0            0.0   \n",
       "317196      0.0     91.0      1.0     689.0            NaN            NaN   \n",
       "\n",
       "        NAS_DELAY  SECURITY_DELAY  LATE_AIRCRAFT_DELAY  Unnamed: 31  \n",
       "19905         NaN             NaN                  NaN          NaN  \n",
       "92968         NaN             NaN                  NaN          NaN  \n",
       "87542         NaN             NaN                  NaN          NaN  \n",
       "107699        0.0             0.0                 63.0          NaN  \n",
       "317196        NaN             NaN                  NaN          NaN  \n",
       "\n",
       "[5 rows x 32 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "airline_raw = data.sample(n=100000, random_state=100)\n",
    "del data\n",
    "airline_raw.head()\n",
    "#data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Cleaning:\n",
    "1. For consistency, we will lower case all column names. \n",
    "2. We will also drop the last column as it has all null values. \n",
    "3. We will convert the individual date columns to 1 datetime column and drop unnecessory columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "airline_raw.columns = airline_raw.columns.str.lower() # lower case all column names for consistency\n",
    "\n",
    "airline_raw = airline_raw.drop(airline_raw.columns[-1],axis=1) # drop last column\n",
    "\n",
    "# convert date and months columns to datetime and remove individual columns\n",
    "\n",
    "airline_raw['date'] = pd.to_datetime(airline_raw[['day_of_month','month','year']].astype(str).apply(' '.join, 1), format='%d %m %Y')\n",
    "\n",
    "airline_raw.drop(['day_of_month','month','year'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Understand and Fix NULL Values\n",
    "We will evaluate the NULL values in the data and decide if we need to remove the NULL values or keep them. We are especially interested in the column 'arr_delay'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing = airline_raw.isnull().mean()*100\n",
    "missing_values = pd.DataFrame({'column_name': airline_raw.columns,\n",
    "                                 'percent_missing': missing})\n",
    "print(missing_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,8))\n",
    "sns.barplot(x='column_name',y='percent_missing',data=missing_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we see that wherever a flight is cancelled as mentioned in the 'cancelled' column, the arrival time is null. So considering the scope of our analysis, we will only keep the data for the flights which are not cancelled."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "cancel = airline_raw[airline_raw.cancelled==1].copy() # get cancellation data in separate df\n",
    "\n",
    "airline = airline_raw[airline_raw.cancelled==0].copy() # remove cancellation data from the full data\n",
    "\n",
    "airline.drop(['cancelled','cancellation_code'], axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "airline.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now check again to see if we have some Nulls or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check for NA in arrival time\n",
    "airline.arr_delay.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Arrival delay column still has some NULL values, lets explore those."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Arrival delay column still has some NULL values, lets explore those.\n",
    "\n",
    "airline[airline.arr_delay.isnull()==True].describe()\n",
    "\n",
    "# Seems like all NAs are from flights which have been diverted. Lets verify that.\n",
    "\n",
    "airline[airline.diverted==0].arr_delay.isnull().sum() # This verifies that no arrival time is listed for diverted flights."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we see that wherever a flight is diverted as mentioned in the 'diverted' column, the arrival time is null. So considering the scope of our analysis, we will only keep the data for the flights which are not diverted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# No arrival time listed for diverted flights, store diverted flights data in deparate df\n",
    "divert = airline[airline.diverted==1].copy()\n",
    "airline = airline[airline.diverted==0]\n",
    "airline.drop(['diverted'], axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now explore the output column to check for any extreme values and see the distribution. We have the following observations:\n",
    "1. There are negative values in the arrival delay column. These values actually are correct and correspond to the occurence where the flight landed earlier then scheduled.\n",
    "2. There are some very delayed flights (more than 800 minutes ~ 13 hours). These flights also are legit delays for several reasons, so we will keep these in our data as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(airline.arr_delay)\n",
    "airline.arr_delay.describe()\n",
    "\n",
    "## Check max values for airline delay\n",
    "airline.arr_delay.sort_values(ascending=False)\n",
    "print(airline[airline.arr_delay>800].head()) # the delay looks legit and we will keep these extreme values\n",
    "\n",
    "## Check min values for airline delay\n",
    "airline.arr_delay.sort_values(ascending=True).head(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(airline.arr_delay)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a flag for delayed flight. If the flight is more than 15 minutes late, then we will consider it as late."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "airline['delayed'] = (airline.arr_delay > 15).astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "airline.delayed.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleaning for independent variables\n",
    "1. We will create all the categorical variables into categories for future analysis.\n",
    "2. We will only keep independent variables which will be used in model and are available before the flight takes off."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sns.pairplot(airline)\n",
    "#[['UniqueCarrier', 'FlightNum', 'TailNum', 'Origin', 'Dest']]\n",
    "airline.origin_city_name.value_counts()\n",
    "#airline.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "var = ['op_unique_carrier', 'tail_num', 'op_carrier_fl_num', 'origin',\n",
    "       'origin_city_name', 'origin_state_nm', 'dest', 'dest_city_name',\n",
    "       'dest_state_nm']\n",
    "for v in var:\n",
    "    airline[v] = airline[v].astype('category')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# only keep variables which will be used in model and are available before hand\n",
    "\n",
    "airline_model = airline[['op_unique_carrier', 'tail_num', 'op_carrier_fl_num', 'origin',\n",
    "                         'origin_city_name', 'origin_state_nm', 'dest', 'dest_city_name',\n",
    "                         'dest_state_nm','crs_dep_time','crs_arr_time','air_time','distance','date','delayed']].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now analyze some of the independent variables to be used in the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check delayed flights by destination \n",
    "\n",
    "by_orig = airline_model.groupby('dest').agg(['sum', 'count'])['delayed'].sort_values(by='sum',ascending=False).cumsum()\n",
    "#by_orig\n",
    "by_orig = by_orig.reset_index()\n",
    "#by_orig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,8))\n",
    "\n",
    "plt.subplot(1,2,1)\n",
    "plt.grid()\n",
    "plt.plot(by_orig['sum']*100/by_orig['sum'].max(),'bo')\n",
    "plt.title('Delayed Flights')\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "plt.grid()\n",
    "plt.plot(by_orig['count']*100/by_orig['count'].max(),'bo')\n",
    "plt.title('Total Flights')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We choose top 100 cities, because that makes up more than 90% of data.\n",
    "airline_top_100 = airline_model[airline_model['dest'].isin(by_orig.dest.head(100))]\n",
    "airline_top_100.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# group by carrier and check the percentage of flights delayed\n",
    "airline_model.groupby('op_unique_carrier').mean()['delayed']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation of the numeric columns with delay of arrival\n",
    "airline_model.corr()['delayed']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot total delayed flight on each day\n",
    "\n",
    "plt.figure(figsize=(15,8))\n",
    "\n",
    "plot = airline_model.groupby('date').agg(['sum','count'])['delayed'].reset_index()\n",
    "#plot.head()\n",
    "#pd.melt(plot,id_vars=['date'],value_vars=['sum','count']).head(10)\n",
    "\n",
    "sns.lineplot(x='date', y='value', hue='variable',data=pd.melt(plot,id_vars=['date'],value_vars=['sum','count']), palette=\"tab10\", linewidth=2.5)\n",
    "\n",
    "# there is not much we can deduce from daily delayed flights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# considering that sun rises at 7AM and sets at 5PM, we will check whether there is any pattern in flights landing \n",
    "# during the day or night.\n",
    "\n",
    "#airline_model.crs_arr_time > 700\n",
    "\n",
    "#airline_model.loc[airline_model['A'] == df['B'], 'C'] = 0\n",
    "airline_model.loc[airline_model['crs_arr_time'] < 1700, 'arr_daytime'] = 1\n",
    "airline_model.loc[airline_model['crs_arr_time'] > 700, 'arr_daytime'] = 1\n",
    "airline_model.loc[airline_model['crs_arr_time'] < 700, 'arr_daytime'] = 0\n",
    "airline_model.loc[airline_model['crs_arr_time'] > 1700, 'arr_daytime'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,8))\n",
    "sns.factorplot(x='delayed', col='arr_daytime', kind='count', data=airline_model);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can clearly see that flights scheduled to arrive during the night time have a high chance of being delayed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# considering that sun rises at 7AM and sets at 5PM, we will check whether there is any pattern in flights departing \n",
    "# during the day or night.\n",
    "\n",
    "\n",
    "airline_model.loc[airline_model['crs_dep_time'] < 1700, 'dep_daytime'] = 1\n",
    "airline_model.loc[airline_model['crs_dep_time'] > 700, 'dep_daytime'] = 1\n",
    "airline_model.loc[airline_model['crs_dep_time'] < 700, 'dep_daytime'] = 0\n",
    "airline_model.loc[airline_model['crs_dep_time'] > 1700, 'dep_daytime'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,8))\n",
    "sns.factorplot(x='delayed', col='dep_daytime', kind='count', data=airline_model);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,8))\n",
    "sns.distplot(airline_model.distance, kde=False);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,8))\n",
    "airline_model.groupby('delayed').air_time.hist(alpha=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "airline_model.groupby('delayed').distance.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "airline_model.groupby('delayed').air_time.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>crs_dep_time</th>\n",
       "      <th>crs_arr_time</th>\n",
       "      <th>air_time</th>\n",
       "      <th>distance</th>\n",
       "      <th>delayed</th>\n",
       "      <th>arr_daytime</th>\n",
       "      <th>dep_daytime</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dow</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Friday</th>\n",
       "      <td>1332.461604</td>\n",
       "      <td>1478.035546</td>\n",
       "      <td>110.203162</td>\n",
       "      <td>802.778145</td>\n",
       "      <td>0.203653</td>\n",
       "      <td>0.563829</td>\n",
       "      <td>0.605074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Monday</th>\n",
       "      <td>1336.581825</td>\n",
       "      <td>1483.889814</td>\n",
       "      <td>110.122378</td>\n",
       "      <td>804.663309</td>\n",
       "      <td>0.177887</td>\n",
       "      <td>0.558803</td>\n",
       "      <td>0.610299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Saturday</th>\n",
       "      <td>1301.537248</td>\n",
       "      <td>1468.377832</td>\n",
       "      <td>113.778759</td>\n",
       "      <td>837.515239</td>\n",
       "      <td>0.143560</td>\n",
       "      <td>0.591689</td>\n",
       "      <td>0.647216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sunday</th>\n",
       "      <td>1353.931584</td>\n",
       "      <td>1495.042877</td>\n",
       "      <td>111.748672</td>\n",
       "      <td>817.104342</td>\n",
       "      <td>0.189160</td>\n",
       "      <td>0.549360</td>\n",
       "      <td>0.608091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Thursday</th>\n",
       "      <td>1336.466126</td>\n",
       "      <td>1474.067264</td>\n",
       "      <td>110.011745</td>\n",
       "      <td>797.184113</td>\n",
       "      <td>0.238482</td>\n",
       "      <td>0.560211</td>\n",
       "      <td>0.605134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Tuesday</th>\n",
       "      <td>1329.213001</td>\n",
       "      <td>1480.572348</td>\n",
       "      <td>110.167072</td>\n",
       "      <td>796.867080</td>\n",
       "      <td>0.222815</td>\n",
       "      <td>0.563398</td>\n",
       "      <td>0.609798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Wednesday</th>\n",
       "      <td>1321.536992</td>\n",
       "      <td>1465.851796</td>\n",
       "      <td>109.883197</td>\n",
       "      <td>796.388946</td>\n",
       "      <td>0.222980</td>\n",
       "      <td>0.572199</td>\n",
       "      <td>0.611212</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           crs_dep_time  crs_arr_time    air_time    distance   delayed  \\\n",
       "dow                                                                       \n",
       "Friday      1332.461604   1478.035546  110.203162  802.778145  0.203653   \n",
       "Monday      1336.581825   1483.889814  110.122378  804.663309  0.177887   \n",
       "Saturday    1301.537248   1468.377832  113.778759  837.515239  0.143560   \n",
       "Sunday      1353.931584   1495.042877  111.748672  817.104342  0.189160   \n",
       "Thursday    1336.466126   1474.067264  110.011745  797.184113  0.238482   \n",
       "Tuesday     1329.213001   1480.572348  110.167072  796.867080  0.222815   \n",
       "Wednesday   1321.536992   1465.851796  109.883197  796.388946  0.222980   \n",
       "\n",
       "           arr_daytime  dep_daytime  \n",
       "dow                                  \n",
       "Friday        0.563829     0.605074  \n",
       "Monday        0.558803     0.610299  \n",
       "Saturday      0.591689     0.647216  \n",
       "Sunday        0.549360     0.608091  \n",
       "Thursday      0.560211     0.605134  \n",
       "Tuesday       0.563398     0.609798  \n",
       "Wednesday     0.572199     0.611212  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check any patterns in day of week\n",
    "\n",
    "airline_model['dow'] = airline_model.date.dt.day_name()\n",
    "\n",
    "airline_model.groupby('dow').mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Done with EDA for now.\n",
    "#### Lets check the final data structure that we have and see if we need to clean it one final time before model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "airline_model.tail_num.describe()\n",
    "\n",
    "# lets drop the following columns because they have too many distinct values:\n",
    "    #[tail_num,op_carrier_fl_num,crs_dep_time,crs_arr_time]\n",
    "    \n",
    "airline_final = airline_model.drop((('tail_num,op_carrier_fl_num,crs_dep_time,crs_arr_time,date,origin_city_name,origin_state_nm,dest_city_name,dest_state_nm').split(',')),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "airline_final.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply the one-hot encoding to categorical variables to be used in the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "airline_final = pd.get_dummies(airline_final, columns=['op_unique_carrier','origin','dest','dow'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split data into test and train before proceeding to modelling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use train_test_split to split data for model\n",
    "\n",
    "y = airline_final['delayed']\n",
    "X = airline_final.drop('delayed',axis=1)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert to arrays for use with scikit-learn\n",
    "\n",
    "X_train = X_train.values\n",
    "X_test = X_test.values\n",
    "y_train = y_train.values\n",
    "y_test = y_test.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision tree classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate model and fit to data\n",
    "clf = tree.DecisionTreeClassifier(max_depth=3)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "pred = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dot_data = tree.export_graphviz(clf, out_file=None,feature_names=X.columns, \n",
    "                                class_names='delayed',filled=True, rounded=True,special_characters=True) \n",
    "graph = graphviz.Source(dot_data) \n",
    "graph.render(\"sample\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compute accuracy on the training set\n",
    "print (\"Training Accuracy: {} \".format(clf.score(X_train, y_train)))\n",
    "\n",
    "#Compute accuracy on the testing set\n",
    "print (\"Test Accuracy: {} \".format(clf.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot a graph for max depth vs accuracy to find the optimum value of depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dep = np.arange(1, 9)\n",
    "train_accuracy = np.empty(len(dep))\n",
    "test_accuracy = np.empty(len(dep))\n",
    "\n",
    "# Loop over different values of k\n",
    "for i, k in enumerate(dep):\n",
    "    # Setup a Decision Tree Classifier\n",
    "    clf = tree.DecisionTreeClassifier(max_depth=k)\n",
    "\n",
    "    # Fit the classifier to the training data\n",
    "    clf.fit(X_train, y_train)\n",
    "\n",
    "    #Compute accuracy on the training set\n",
    "    train_accuracy[i] = clf.score(X_train, y_train)\n",
    "\n",
    "    #Compute accuracy on the testing set\n",
    "    test_accuracy[i] = clf.score(X_test, y_test)\n",
    "\n",
    "# Generate plot\n",
    "plt.title('clf: Varying depth of tree')\n",
    "plt.plot(dep, test_accuracy, label = 'Testing Accuracy')\n",
    "plt.plot(dep, train_accuracy, label = 'Training Accuracy')\n",
    "plt.legend()\n",
    "plt.xlabel('Depth of tree')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have a big jump in the Accuracy if we increase the depth from 3 to 4 so we will re run the model with max depth = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate model and fit to data\n",
    "clf = tree.DecisionTreeClassifier(max_depth=4)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "pred = clf.predict(X_test)\n",
    "\n",
    "dot_data = tree.export_graphviz(clf, out_file=None,feature_names=X.columns, \n",
    "                                class_names='delayed',filled=True, rounded=True,special_characters=True) \n",
    "graph = graphviz.Source(dot_data) \n",
    "graph.render(\"output\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pred' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-122-b6ee70a3d6c3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclassification_report\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcrosstab\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'pred' is not defined"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, pred))\n",
    "\n",
    "print(pd.crosstab(y_test, pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Recall for predicting the delayed flights has increased from 1% to 3%!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forrest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\saleh\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:737: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n"
     ]
    }
   ],
   "source": [
    "# Import the model we are using\n",
    "\n",
    "min_leaf_samples = 0.03\n",
    "\n",
    "# Instantiate model with 1000 decision trees\n",
    "rf = RandomForestRegressor(n_estimators = 10, random_state = 100,oob_score = True)#,#max_depth=10,\n",
    "                           #min_samples_leaf=round(min_leaf_samples*len(X_train)))\n",
    "# Train the model on training data\n",
    "rf.fit(X_train, y_train);\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not going to print the tree since it has too many nodes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Extract the tree\n",
    "# rf_tree = rf.estimators_[5]\n",
    "# # Save the tree\n",
    "\n",
    "# dot_data = export_graphviz(rf_tree, out_file=None,feature_names=X.columns, \n",
    "#                             class_names='delayed',filled=True, rounded=True,special_characters=True) \n",
    "# graph = graphviz.Source(dot_data) \n",
    "# graph.render(\"rf_output\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the model predictions on the test data and check the precision and recall."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.82      0.83     15664\n",
      "           1       0.33      0.36      0.35      3937\n",
      "\n",
      "    accuracy                           0.73     19601\n",
      "   macro avg       0.59      0.59      0.59     19601\n",
      "weighted avg       0.74      0.73      0.73     19601\n",
      "\n",
      "col_0      0     1\n",
      "row_0             \n",
      "0      12804  2860\n",
      "1       2504  1433\n"
     ]
    }
   ],
   "source": [
    "rf_pred = (rf.predict(X_test)> 0.3).astype(int)\n",
    "\n",
    "print(classification_report(y_test, rf_pred))\n",
    "\n",
    "print(pd.crosstab(y_test, rf_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Score: 0.80 \n",
      " OOB Score: -0.26 \n",
      " Validation Score: -0.09\n"
     ]
    }
   ],
   "source": [
    "print('Training Score: {:.2f} \\n OOB Score: {:.2f} \\n Validation Score: {:.2f}'.format(rf.score(X_train, y_train),rf.oob_score_,rf.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we see that random forrest is not giving us a good validation score. We only get a good training score that means that model is over fitting and will not be able to predict on unknown data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Importance\n",
    "Not going to use for the case of Random Forrest as the model is useless itself"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get numerical feature importances\n",
    "importances = list(rf.feature_importances_)\n",
    "# List of tuples with variable and importance\n",
    "feature_importances = [(feature, round(importance, 2)) for feature, importance in zip(X.columns, importances)]\n",
    "# Sort the feature importances by most important first\n",
    "feature_importances = sorted(feature_importances, key = lambda x: x[1], reverse = True)\n",
    "# Print out the feature and importances \n",
    "#[print('Variable: {:25} Importance: {}'.format(*pair)) for pair in feature_importances];"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
